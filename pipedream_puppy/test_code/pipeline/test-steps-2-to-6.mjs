/**
 * Step 2~6 í…ŒìŠ¤íŠ¸ (ì´ë¯¸ì§€ ìƒì„± ìŠ¤í‚µ)
 * ê¸°ì¡´ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´ì„œ TTS â†’ ìë§‰ â†’ ë¹„ë””ì˜¤ â†’ BGM â†’ í•©ì„± í…ŒìŠ¤íŠ¸
 *
 * ì‹¤í–‰: node test-steps-2-to-6.mjs
 */

import axios from 'axios';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import FormData from 'form-data';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// =====================
// í™˜ê²½ ì„¤ì •
// =====================
const CONFIG = {
  GEMINI_API_KEY: process.env.GEMINI_API_KEY || '',
  HEDRA_API_KEY: process.env.HEDRA_API_KEY || '',
  ELEVENLABS_API_KEY: process.env.ELEVENLABS_API_KEY || '',
  OPENAI_API_KEY: process.env.OPENAI_API_KEY || '',
  MUSICAPI_KEY: process.env.MUSICAPI_KEY || '',
  CREATOMATE_API_KEY: process.env.CREATOMATE_API_KEY || '',

  // ElevenLabs ìŒì„± ì„¤ì •
  VOICE_PUPPY: process.env.VOICE_PUPPY || 'ocZQ262SsZb9RIxcQBOj', // Lulu Lollipop - ê·€ì—¬ìš´ ì•„ê¸° ëª©ì†Œë¦¬ (high-pitched, giggly, youthful)
  VOICE_OWNER: process.env.VOICE_OWNER || 'iP95p4xoKVk53GoZ742B', // Chris (casual, middle-aged male) - ì¸ìí•œ ë‚¨ì„± ëª©ì†Œë¦¬

  // ê¸°ì¡´ ì´ë¯¸ì§€ í´ë”
  EXISTING_FOLDER: 'test_20251129_348fc310',
  OUTPUT_DIR: path.join(__dirname, 'test_output'),
};

// =====================
// í…ŒìŠ¤íŠ¸ìš© ê³ ì • ìŠ¤í¬ë¦½íŠ¸ (ë•…ì½©ì´)
// =====================
const FIXED_SCRIPT = {
  folder_name: CONFIG.EXISTING_FOLDER, // ê¸°ì¡´ í´ë” ì‚¬ìš©
  language: 'korean',
  title: {
    korean: 'ë•…ì½©ì´ì˜ ì‚¬ìí›„ vs ë¯¸ì–´ìº£',
    japanese: 'ë•…ì½©ã®ç…å­å¼ vs ãƒŸãƒ¼ã‚¢ã‚­ãƒ£ãƒƒãƒˆ',
    english: "Peanut's Lion Roar vs Meerkat"
  },

  characters: {
    puppy: {
      name: 'ë•…ì½©',
      voice_type: 'female_child',
      voice_description: 'cute baby-like female voice'
    },
    owner: {
      name: 'ì•„ë¹ ',
      voice_type: 'male_adult',
      voice_description: 'warm gentle male voice'
    }
  },

  puppy_character: {
    name: 'ë•…ì½©',
    breed: 'Pomeranian',
    image_prompt: 'cute fluffy orange Pomeranian puppy, small round face, bright dark eyes, fluffy orange-cream fur, tiny black nose, pointed ears, adorable expression'
  },

  script_segments: [
    {
      index: 1,
      speaker: 'puppy',
      narration: 'ì•„ë¹ ! ë•…ì½©ì´ ì‚¬ìí›„ ë³´ì—¬ì¤„ê¹Œ? ì–´í¥! ë‚´ê°€ ì œì¼ ì„ë‹¤!',
      emotion: 'excited',
      puppy_pose: 'standing proudly with chest out, mouth open like roaring',
      background: 'cozy living room with soft lighting',
      start_time: 0,
      end_time: 5,
      duration: 5
    },
    {
      index: 2,
      speaker: 'owner',
      narration: 'ìš°ë¦¬ ë•…ì½©ì´ ì§„ì§œ í˜¸ë‘ì´ë„¤! ìœ¼ë¥´ë !',
      emotion: 'amused',
      puppy_pose: 'looking up at camera with happy smile',
      background: 'cozy living room with soft lighting',
      start_time: 5,
      end_time: 8,
      duration: 3
    },
    {
      index: 3,
      speaker: 'puppy',
      narration: 'ì—í—¤í—¤... ì´ë²ˆì—” ë¯¸ì–´ìº£! ë•…ì½©ì´ ë¯¸ì–´ìº£ë„ ì˜í•´! ì­?',
      emotion: 'playful',
      puppy_pose: 'standing on hind legs like meerkat, looking around',
      background: 'cozy living room with soft lighting',
      start_time: 8,
      end_time: 13,
      duration: 5
    },
    {
      index: 4,
      speaker: 'owner',
      narration: 'ê·¸ë˜, ë•…ì½©ì´ ë¯¸ì–´ìº£ì²˜ëŸ¼ ë‘ë¦¬ë²ˆë‘ë¦¬ë²ˆ í•´ë´!',
      emotion: 'encouraging',
      puppy_pose: 'standing on hind legs, looking left and right curiously',
      background: 'cozy living room with soft lighting',
      start_time: 13,
      end_time: 16,
      duration: 3
    },
    {
      index: 5,
      speaker: 'puppy',
      narration: 'ì­? ì­? êº„ì•…! í„¸ ì –ì—ˆì–´! ë¯¸ì–´ìº£ ì•„ë‹ˆê³  ë¬¼ì— ë¹ ì§„ ì¥ë‹¤!',
      emotion: 'surprised',
      puppy_pose: 'wet fur, shocked wide eyes, water droplets on face',
      background: 'bathroom with tiles, water splashes',
      start_time: 16,
      end_time: 22,
      duration: 6
    },
    {
      index: 6,
      speaker: 'owner',
      narration: 'ì•„ì´ê³ , ìš°ë¦¬ ë•…ì½©ì´ ì¥ëŒì´ ëë„¤! ê´œì°®ì•„, ì•„ë¹ ê°€ ë‹¦ì•„ì¤„ê²Œ!',
      emotion: 'loving',
      puppy_pose: 'wrapped in fluffy white towel, only face visible, cute look',
      background: 'warm cozy bathroom',
      start_time: 22,
      end_time: 27,
      duration: 5
    }
  ],

  total_duration_seconds: 27
};

// =====================
// ê¸°ì¡´ ì´ë¯¸ì§€ ë¡œë“œ
// =====================
function loadExistingImages(script) {
  console.log('\nğŸ“¸ [STEP 1] ê¸°ì¡´ ì´ë¯¸ì§€ ë¡œë“œ...');

  const outputFolder = path.join(CONFIG.OUTPUT_DIR, script.folder_name);
  const results = [];

  for (const segment of script.script_segments) {
    const filename = `scene_${String(segment.index).padStart(3, '0')}.png`;
    const filepath = path.join(outputFolder, filename);

    if (fs.existsSync(filepath)) {
      results.push({
        index: segment.index,
        filename,
        filepath,
        narration: segment.narration,
        speaker: segment.speaker,
        emotion: segment.emotion,
        puppy_pose: segment.puppy_pose,
        duration: segment.duration,
        start: segment.start_time,
        end: segment.end_time
      });
      console.log(`  âœ“ ${filename} (${segment.speaker})`);
    } else {
      console.log(`  âœ— ${filename} ì—†ìŒ`);
    }
  }

  console.log(`\nğŸ“¸ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ: ${results.length}/${script.script_segments.length}`);
  return results;
}

// =====================
// 2. ìŒì„± ìƒì„± (ElevenLabs TTS - Speakerë³„)
// =====================
async function generateTTS(script) {
  console.log('\nğŸ¤ [STEP 2] ìŒì„± ìƒì„± (ElevenLabs TTS)...');

  if (!CONFIG.ELEVENLABS_API_KEY) {
    console.log('  âš ï¸ ELEVENLABS_API_KEY ì—†ìŒ - TTS ìŠ¤í‚µ');
    return [];
  }

  const outputFolder = path.join(CONFIG.OUTPUT_DIR, script.folder_name);
  const results = [];

  for (const segment of script.script_segments) {
    const voiceId = segment.speaker === 'puppy' ? CONFIG.VOICE_PUPPY : CONFIG.VOICE_OWNER;
    const speakerIcon = segment.speaker === 'puppy' ? 'ğŸ•' : 'ğŸ‘¤';

    console.log(`  - Scene ${segment.index} ${speakerIcon} [${segment.speaker}]: "${segment.narration.substring(0, 25)}..."`);

    try {
      const response = await axios.post(
        `https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`,
        {
          text: segment.narration,
          model_id: 'eleven_multilingual_v2',
          voice_settings: {
            stability: 0.5,
            similarity_boost: 0.75,
          },
        },
        {
          headers: {
            'xi-api-key': CONFIG.ELEVENLABS_API_KEY,
            'Content-Type': 'application/json',
            'Accept': 'audio/mpeg',
          },
          responseType: 'arraybuffer',
        }
      );

      const audioBuffer = Buffer.from(response.data);
      const audioFilename = `audio_${String(segment.index).padStart(3, '0')}.mp3`;
      const audioFilepath = path.join(outputFolder, audioFilename);
      fs.writeFileSync(audioFilepath, audioBuffer);

      results.push({
        index: segment.index,
        filename: audioFilename,
        filepath: audioFilepath,
        speaker: segment.speaker,
        narration: segment.narration,
        duration: segment.duration,
        start: segment.start_time,
        end: segment.end_time,
      });

      console.log(`    âœ“ ì €ì¥: ${audioFilename} (${(audioBuffer.length / 1024).toFixed(1)}KB)`);

    } catch (error) {
      console.error(`    âœ— Scene ${segment.index} TTS ì‹¤íŒ¨:`, error.response?.data || error.message);
    }

    await new Promise(r => setTimeout(r, 500));
  }

  console.log(`\nğŸ¤ TTS ìƒì„± ì™„ë£Œ: ${results.length}/${script.script_segments.length}`);
  return results;
}

// =====================
// 3. ìë§‰ ìƒì„± (Whisper ë˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ ê¸°ë°˜)
// =====================
async function generateSubtitles(audioFiles, script) {
  console.log('\nğŸ“ [STEP 3] ìë§‰ ìƒì„±...');

  const outputFolder = path.join(CONFIG.OUTPUT_DIR, script.folder_name);

  // Whisper ì—†ìœ¼ë©´ ìŠ¤í¬ë¦½íŠ¸ ê¸°ë°˜ ìë§‰ ì‚¬ìš©
  if (!CONFIG.OPENAI_API_KEY || audioFiles.length === 0) {
    console.log('  â†’ ìŠ¤í¬ë¦½íŠ¸ ê¸°ë°˜ ìë§‰ ì‚¬ìš©');

    const results = script.script_segments.map(seg => ({
      index: seg.index,
      start: seg.start_time,
      end: seg.end_time,
      text: seg.narration,
      speaker: seg.speaker,
    }));

    // SRT íŒŒì¼ ì €ì¥
    const srtContent = results.map((sub, i) => {
      const formatTime = (seconds) => {
        const h = Math.floor(seconds / 3600);
        const m = Math.floor((seconds % 3600) / 60);
        const s = Math.floor(seconds % 60);
        const ms = Math.round((seconds % 1) * 1000);
        return `${String(h).padStart(2, '0')}:${String(m).padStart(2, '0')}:${String(s).padStart(2, '0')},${String(ms).padStart(3, '0')}`;
      };
      return `${i + 1}\n${formatTime(sub.start)} --> ${formatTime(sub.end)}\n${sub.text}\n`;
    }).join('\n');

    fs.writeFileSync(path.join(outputFolder, 'subtitles.srt'), srtContent);
    fs.writeFileSync(path.join(outputFolder, 'subtitles.json'), JSON.stringify(results, null, 2));

    console.log(`\nğŸ“ ìë§‰ ìƒì„± ì™„ë£Œ: ${results.length}ê°œ ì„¸ê·¸ë¨¼íŠ¸`);
    return results;
  }

  // Whisper ì‚¬ìš©
  console.log('  â†’ Whisperë¡œ ìë§‰ ìƒì„±...');
  const results = [];
  let cumulativeTime = 0;

  for (const audio of audioFiles) {
    console.log(`  - Scene ${audio.index}: ${audio.filename}`);

    try {
      const audioBuffer = fs.readFileSync(audio.filepath);

      const formData = new FormData();
      formData.append('file', audioBuffer, {
        filename: 'audio.mp3',
        contentType: 'audio/mpeg',
      });
      formData.append('model', 'whisper-1');
      formData.append('language', 'ko');
      formData.append('response_format', 'verbose_json');
      formData.append('timestamp_granularities[]', 'segment');

      const response = await axios.post(
        'https://api.openai.com/v1/audio/transcriptions',
        formData,
        {
          headers: {
            'Authorization': `Bearer ${CONFIG.OPENAI_API_KEY}`,
            ...formData.getHeaders(),
          },
        }
      );

      const segments = response.data.segments || [];
      for (const seg of segments) {
        results.push({
          index: audio.index,
          start: cumulativeTime + seg.start,
          end: cumulativeTime + seg.end,
          text: seg.text.trim(),
          speaker: audio.speaker,
        });
      }

      cumulativeTime += response.data.duration || audio.duration;
      console.log(`    âœ“ ${segments.length}ê°œ ì„¸ê·¸ë¨¼íŠ¸ (${response.data.duration?.toFixed(1)}ì´ˆ)`);

    } catch (error) {
      console.error(`    âœ— Whisper ì‹¤íŒ¨:`, error.response?.data || error.message);

      // ì‹¤íŒ¨ ì‹œ ìŠ¤í¬ë¦½íŠ¸ ê¸°ë°˜ ìë§‰ ì¶”ê°€
      const seg = script.script_segments.find(s => s.index === audio.index);
      if (seg) {
        results.push({
          index: seg.index,
          start: seg.start_time,
          end: seg.end_time,
          text: seg.narration,
          speaker: seg.speaker,
        });
      }
    }

    await new Promise(r => setTimeout(r, 500));
  }

  // SRT íŒŒì¼ ì €ì¥
  const srtContent = results.map((sub, i) => {
    const formatTime = (seconds) => {
      const h = Math.floor(seconds / 3600);
      const m = Math.floor((seconds % 3600) / 60);
      const s = Math.floor(seconds % 60);
      const ms = Math.round((seconds % 1) * 1000);
      return `${String(h).padStart(2, '0')}:${String(m).padStart(2, '0')}:${String(s).padStart(2, '0')},${String(ms).padStart(3, '0')}`;
    };
    return `${i + 1}\n${formatTime(sub.start)} --> ${formatTime(sub.end)}\n${sub.text}\n`;
  }).join('\n');

  fs.writeFileSync(path.join(outputFolder, 'subtitles.srt'), srtContent);
  fs.writeFileSync(path.join(outputFolder, 'subtitles.json'), JSON.stringify(results, null, 2));

  console.log(`\nğŸ“ ìë§‰ ìƒì„± ì™„ë£Œ: ${results.length}ê°œ ì„¸ê·¸ë¨¼íŠ¸`);
  return results;
}

// =====================
// 4. ë¹„ë””ì˜¤ ìƒì„± (Speakerë³„ ë¶„ê¸°: puppyâ†’Hedra, ownerâ†’Veo)
// =====================
async function generateVideos(images, audioFiles, script) {
  console.log('\nğŸ¬ [STEP 4] ë¹„ë””ì˜¤ ìƒì„± ì‹œì‘ (Speakerë³„ ë¶„ê¸°)...');
  console.log('  - puppy (ê°•ì•„ì§€ ëŒ€ì‚¬) â†’ Hedra (ë¦½ì‹±í¬)');
  console.log('  - owner (ì£¼ì¸ ëŒ€ì‚¬) â†’ Veo (ëª¨ì…˜)');

  const outputFolder = path.join(CONFIG.OUTPUT_DIR, script.folder_name);
  const results = [];

  // Hedra ëª¨ë¸ ID ì¡°íšŒ - Hedra Character 3 (requires_audio_input: true)
  // d1dd37a3-e39a-4854-a298-6510289f9cf2 = Hedra Character 3 (ë¦½ì‹±í¬ìš©)
  const HEDRA_CHARACTER_3_MODEL_ID = 'd1dd37a3-e39a-4854-a298-6510289f9cf2';
  let hedraModelId = null;
  if (CONFIG.HEDRA_API_KEY) {
    try {
      const modelsResponse = await axios.get('https://api.hedra.com/web-app/public/models', {
        headers: { 'x-api-key': CONFIG.HEDRA_API_KEY }
      });
      // Hedra Character 3 ëª¨ë¸ ì°¾ê¸° (requires_audio_input: true)
      const character3Model = modelsResponse.data?.find(m =>
        m.name?.includes('Character 3') || m.requires_audio_input === true
      );
      hedraModelId = character3Model?.id || HEDRA_CHARACTER_3_MODEL_ID;
      console.log(`  - Hedra ëª¨ë¸: ${hedraModelId} (${character3Model?.name || 'Character 3'})`);
    } catch (e) {
      console.log(`  - Hedra ëª¨ë¸ ì¡°íšŒ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©:`, e.response?.data || e.message);
      hedraModelId = HEDRA_CHARACTER_3_MODEL_ID;
    }
  }

  for (const image of images) {
    const segment = script.script_segments.find(s => s.index === image.index);
    const audio = audioFiles.find(a => a.index === image.index);

    if (segment.speaker === 'puppy') {
      // ========== Hedra (ë¦½ì‹±í¬) ==========
      console.log(`  - Scene ${image.index} [puppyâ†’Hedra]: "${segment.narration.substring(0, 25)}..."`);

      if (!CONFIG.HEDRA_API_KEY || !hedraModelId) {
        console.log(`    âš ï¸ HEDRA_API_KEY ì—†ìŒ ë˜ëŠ” ëª¨ë¸ ì—†ìŒ - ìŠ¤í‚µ`);
        continue;
      }

      try {
        // 1. ì´ë¯¸ì§€ ì—…ë¡œë“œ
        const assetResponse = await axios.post('https://api.hedra.com/web-app/public/assets', {
          name: image.filename,
          type: 'image'
        }, {
          headers: { 'x-api-key': CONFIG.HEDRA_API_KEY, 'Content-Type': 'application/json' }
        });

        const imageBuffer = fs.readFileSync(image.filepath);
        const formData = new FormData();
        formData.append('file', imageBuffer, { filename: image.filename, contentType: 'image/png' });

        await axios.post(`https://api.hedra.com/web-app/public/assets/${assetResponse.data.id}/upload`, formData, {
          headers: { 'x-api-key': CONFIG.HEDRA_API_KEY, ...formData.getHeaders() }
        });

        console.log(`    â†’ ì´ë¯¸ì§€ ì—…ë¡œë“œ ì™„ë£Œ: ${assetResponse.data.id}`);

        // 2. ì˜¤ë””ì˜¤ ì—…ë¡œë“œ (ElevenLabs ì˜¤ë””ì˜¤ ì‚¬ìš©)
        let audioAssetId = null;
        if (audio) {
          const audioAssetResponse = await axios.post('https://api.hedra.com/web-app/public/assets', {
            name: audio.filename,
            type: 'audio'
          }, {
            headers: { 'x-api-key': CONFIG.HEDRA_API_KEY, 'Content-Type': 'application/json' }
          });

          const audioBuffer = fs.readFileSync(audio.filepath);
          const audioFormData = new FormData();
          audioFormData.append('file', audioBuffer, { filename: audio.filename, contentType: 'audio/mpeg' });

          await axios.post(`https://api.hedra.com/web-app/public/assets/${audioAssetResponse.data.id}/upload`, audioFormData, {
            headers: { 'x-api-key': CONFIG.HEDRA_API_KEY, ...audioFormData.getHeaders() }
          });

          audioAssetId = audioAssetResponse.data.id;
          console.log(`    â†’ ì˜¤ë””ì˜¤ ì—…ë¡œë“œ ì™„ë£Œ: ${audioAssetId}`);
        }

        // 3. ë¹„ë””ì˜¤ ìƒì„±
        const durationMs = Math.round(segment.duration * 1000); // ì´ˆ â†’ ë°€ë¦¬ì´ˆ
        const requestData = {
          type: 'video',
          ai_model_id: hedraModelId,
          start_keyframe_id: assetResponse.data.id,
          generated_video_inputs: {
            resolution: '720p',
            aspect_ratio: '9:16',
            text_prompt: segment.narration,
            text: segment.narration,
            duration_ms: durationMs
          }
        };

        if (audioAssetId) {
          requestData.audio_id = audioAssetId;
        }

        const genResponse = await axios.post('https://api.hedra.com/web-app/public/generations', requestData, {
          headers: { 'x-api-key': CONFIG.HEDRA_API_KEY, 'Content-Type': 'application/json' }
        });

        console.log(`    â†’ ë¹„ë””ì˜¤ ìƒì„± ì‹œì‘: ${genResponse.data.id}`);

        // 4. ì™„ë£Œ ëŒ€ê¸°
        let videoUrl = null;
        for (let i = 0; i < 120; i++) {
          await new Promise(r => setTimeout(r, 5000));

          const status = await axios.get(`https://api.hedra.com/web-app/public/generations/${genResponse.data.id}/status`, {
            headers: { 'x-api-key': CONFIG.HEDRA_API_KEY }
          });

          if (status.data.status === 'complete') {
            videoUrl = status.data.url || status.data.download_url;
            break;
          }
          if (status.data.status === 'error') {
            throw new Error(status.data.error_message || 'Unknown error');
          }

          if (i % 6 === 0 && i > 0) console.log(`    ... ëŒ€ê¸° ì¤‘ (${i * 5}ì´ˆ, status: ${status.data.status})`);
        }

        if (videoUrl) {
          const videoResponse = await axios.get(videoUrl, { responseType: 'arraybuffer' });
          const videoFilename = `video_${String(image.index).padStart(3, '0')}_hedra.mp4`;
          const videoFilepath = path.join(outputFolder, videoFilename);
          fs.writeFileSync(videoFilepath, Buffer.from(videoResponse.data));

          results.push({
            index: image.index,
            filename: videoFilename,
            filepath: videoFilepath,
            url: videoFilepath,
            speaker: segment.speaker,
            narration: segment.narration,
            duration: segment.duration,
            start: segment.start_time,
            end: segment.end_time,
            source: 'hedra'
          });

          console.log(`    âœ“ ì €ì¥: ${videoFilename}`);
        }
      } catch (error) {
        console.error(`    âœ— Hedra ì‹¤íŒ¨:`, error.response?.data || error.message);
      }

    } else {
      // ========== Veo (ëª¨ì…˜) ==========
      console.log(`  - Scene ${image.index} [ownerâ†’Veo]: "${segment.narration.substring(0, 25)}..."`);

      try {
        const VEO_BASE_URL = 'https://generativelanguage.googleapis.com/v1beta';
        const VEO_MODEL = 'veo-3.0-fast-generate-001';

        const imageBuffer = fs.readFileSync(image.filepath);
        const imageBase64 = imageBuffer.toString('base64');

        const motionPrompt = `cute puppy listening, ${segment.emotion} expression, ${segment.puppy_pose}, natural subtle movement, breathing, ear twitching, gentle camera movement, high quality video`;

        const createResponse = await axios.post(`${VEO_BASE_URL}/models/${VEO_MODEL}:predictLongRunning`, {
          instances: [{
            prompt: motionPrompt,
            image: {
              bytesBase64Encoded: imageBase64,
              mimeType: 'image/png',
            },
          }],
          parameters: {
            aspectRatio: '9:16',
            durationSeconds: 6,
            personGeneration: 'allow_adult',
          },
        }, {
          headers: {
            'Content-Type': 'application/json',
            'X-goog-api-key': CONFIG.GEMINI_API_KEY,
          },
          timeout: 300000,
        });

        const operationName = createResponse.data.name;
        console.log(`    â†’ Operation: ${operationName?.split('/').pop()}`);

        let videoUrl = null;
        for (let i = 0; i < 72; i++) {
          await new Promise(r => setTimeout(r, 5000));

          const statusResponse = await axios.get(`${VEO_BASE_URL}/${operationName}`, {
            headers: { 'X-goog-api-key': CONFIG.GEMINI_API_KEY },
          });

          if (statusResponse.data.done) {
            if (statusResponse.data.error) {
              throw new Error(`Veo failed: ${statusResponse.data.error.message}`);
            }

            const response = statusResponse.data.response;

            if (response?.generateVideoResponse?.generatedSamples?.[0]?.video?.uri) {
              videoUrl = response.generateVideoResponse.generatedSamples[0].video.uri;
            }
            if (!videoUrl && response?.generatedVideos?.[0]?.video?.uri) {
              videoUrl = response.generatedVideos[0].video.uri;
            }
            if (!videoUrl && response?.videos?.[0]) {
              videoUrl = response.videos[0].gcsUri || response.videos[0].uri;
            }

            if (videoUrl?.startsWith('gs://')) {
              const gsMatch = videoUrl.match(/gs:\/\/([^/]+)\/(.+)/);
              if (gsMatch) {
                videoUrl = `https://storage.googleapis.com/${gsMatch[1]}/${gsMatch[2]}`;
              }
            }

            break;
          }

          if (i % 6 === 0 && i > 0) console.log(`    ... ëŒ€ê¸° ì¤‘ (${i * 5}ì´ˆ)`);
        }

        if (videoUrl) {
          const isVeoUrl = videoUrl.includes('generativelanguage.googleapis.com');
          const downloadHeaders = isVeoUrl ? { 'X-goog-api-key': CONFIG.GEMINI_API_KEY } : {};

          const videoResponse = await axios.get(videoUrl, {
            responseType: 'arraybuffer',
            headers: downloadHeaders,
          });

          const videoFilename = `video_${String(image.index).padStart(3, '0')}_veo.mp4`;
          const videoFilepath = path.join(outputFolder, videoFilename);
          fs.writeFileSync(videoFilepath, Buffer.from(videoResponse.data));

          results.push({
            index: image.index,
            filename: videoFilename,
            filepath: videoFilepath,
            url: videoFilepath,
            speaker: segment.speaker,
            narration: segment.narration,
            duration: segment.duration,
            start: segment.start_time,
            end: segment.end_time,
            source: 'veo',
            audio_filepath: audio?.filepath,
          });

          console.log(`    âœ“ ì €ì¥: ${videoFilename}`);
        }
      } catch (error) {
        console.error(`    âœ— Veo ì‹¤íŒ¨:`, error.response?.data?.error?.message || error.message);
      }
    }

    await new Promise(r => setTimeout(r, 2000));
  }

  const hedraCount = results.filter(v => v.source === 'hedra').length;
  const veoCount = results.filter(v => v.source === 'veo').length;
  console.log(`\nğŸ¬ ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: ${results.length}/${images.length} (Hedra: ${hedraCount}, Veo: ${veoCount})`);

  return results;
}

// =====================
// 5. BGM ìƒì„± (MusicAPI)
// =====================
async function generateBGM(script) {
  console.log('\nğŸµ [STEP 5] BGM ìƒì„± (MusicAPI)...');

  if (!CONFIG.MUSICAPI_KEY) {
    console.log('  âš ï¸ MUSICAPI_KEY ì—†ìŒ - BGM ìŠ¤í‚µ');
    return null;
  }

  try {
    const MUSICAPI_BASE = 'https://api.musicapi.ai/api/v1';
    const bgmTags = 'cute, playful, heartwarming, gentle, warm, background music';

    const createResponse = await axios.post(`${MUSICAPI_BASE}/sonic/create`, {
      mv: 'sonic-v4-5',
      make_instrumental: true,
      custom_mode: true,
      title: 'Shorts_BGM',
      tags: bgmTags,
    }, {
      headers: {
        'Authorization': `Bearer ${CONFIG.MUSICAPI_KEY}`,
        'Content-Type': 'application/json',
      },
    });

    const taskId = createResponse.data.task_id;
    console.log(`  â†’ Task ID: ${taskId}`);

    let bgmUrl = null;
    for (let i = 0; i < 60; i++) {
      await new Promise(r => setTimeout(r, 5000));

      const statusResponse = await axios.get(`${MUSICAPI_BASE}/sonic/task/${taskId}`, {
        headers: { 'Authorization': `Bearer ${CONFIG.MUSICAPI_KEY}` },
      });

      const songs = statusResponse.data.data || [];
      if (songs.length > 0 && songs[0].audio_url && !songs[0].audio_url.includes('audiopipe')) {
        bgmUrl = songs[0].audio_url;
        break;
      }

      if (i % 6 === 0 && i > 0) console.log(`    ... ëŒ€ê¸° ì¤‘ (${i * 5}ì´ˆ)`);
    }

    if (bgmUrl) {
      console.log(`  âœ“ BGM ìƒì„± ì™„ë£Œ: ${bgmUrl.substring(0, 60)}...`);
      return bgmUrl;
    }

  } catch (error) {
    console.error('  âœ— BGM ìƒì„± ì‹¤íŒ¨:', error.response?.data || error.message);
  }

  return null;
}

// =====================
// 6. ìµœì¢… í•©ì„± ì•ˆë‚´ (Creatomate ë˜ëŠ” ffmpeg)
// =====================
async function composeFinalVideo(videos, subtitles, script, bgmUrl) {
  console.log('\nğŸ¥ [STEP 6] ìµœì¢… ì˜ìƒ í•©ì„±...');

  const outputFolder = path.join(CONFIG.OUTPUT_DIR, script.folder_name);
  const sortedVideos = [...videos].sort((a, b) => a.index - b.index);

  // ffmpeg concat íŒŒì¼ ìƒì„±
  const concatFilepath = path.join(outputFolder, 'concat.txt');
  const concatContent = sortedVideos.map(v => `file '${v.filename}'`).join('\n');
  fs.writeFileSync(concatFilepath, concatContent);

  // Creatomate source ìƒì„±
  let currentTime = 0;
  const elements = [];

  elements.push({
    type: 'shape',
    shape: 'rectangle',
    width: '100%',
    height: '100%',
    fill_color: '#F5F5F5',
    time: 0,
  });

  for (const video of sortedVideos) {
    const duration = video.duration || 5;

    elements.push({
      type: 'video',
      source: video.url,
      time: currentTime,
      duration,
      fit: 'contain',
    });

    if (video.source === 'hedra') {
      elements.push({
        type: 'audio',
        source: video.url,
        time: currentTime,
        duration,
        volume: '100%',
      });
    } else if (video.audio_filepath) {
      elements.push({
        type: 'audio',
        source: video.audio_filepath,
        time: currentTime,
        duration,
        volume: '100%',
      });
    }

    currentTime += duration;
  }

  const totalDuration = currentTime;

  if (bgmUrl) {
    elements.push({
      type: 'audio',
      source: bgmUrl,
      time: 0,
      duration: totalDuration,
      volume: '20%',
      audio_fade_out: '2s',
    });
  }

  for (const sub of subtitles) {
    if (sub.text?.trim()) {
      elements.push({
        type: 'text',
        text: sub.text.trim(),
        time: sub.start,
        duration: sub.end - sub.start,
        width: '90%',
        x: '50%',
        y: '85%',
        x_anchor: '50%',
        y_anchor: '50%',
        font_family: 'Noto Sans KR',
        font_size: '5vw',
        font_weight: '700',
        fill_color: '#FFFFFF',
        background_color: 'rgba(0,0,0,0.6)',
        background_x_padding: '3%',
        background_y_padding: '2%',
        background_border_radius: '5%',
        text_align: 'center',
      });
    }
  }

  const creatomateSource = {
    output_format: 'mp4',
    width: 1080,
    height: 1920,
    frame_rate: 30,
    duration: totalDuration,
    elements,
  };

  fs.writeFileSync(path.join(outputFolder, 'creatomate_source.json'), JSON.stringify(creatomateSource, null, 2));

  console.log(`  â†’ ì´ ${elements.length}ê°œ ìš”ì†Œ, ${totalDuration}ì´ˆ`);
  console.log('  ğŸ“„ creatomate_source.json ì €ì¥ ì™„ë£Œ');
  console.log('  ğŸ“„ concat.txt ì €ì¥ ì™„ë£Œ');

  console.log('\n  ğŸ“ ffmpeg ìˆ˜ë™ í•©ì„± ëª…ë ¹ì–´:');
  console.log(`  cd "${outputFolder}"`);
  console.log(`  ffmpeg -f concat -safe 0 -i concat.txt -c copy final_output.mp4`);

  return { creatomateSource, outputFolder };
}

// =====================
// ë©”ì¸ ì‹¤í–‰
// =====================
async function main() {
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log('  ğŸ• ë•…ì½©ì´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ (Step 2~6)');
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

  const script = FIXED_SCRIPT;
  const outputFolder = path.join(CONFIG.OUTPUT_DIR, script.folder_name);

  console.log(`\nğŸ“ ê¸°ì¡´ ì´ë¯¸ì§€ í´ë”: ${outputFolder}`);
  console.log(`ğŸ“ ì´ ${script.script_segments.length}ê°œ ì”¬, ${script.total_duration_seconds}ì´ˆ`);

  console.log('\nğŸ”‘ API í‚¤ ìƒíƒœ:');
  console.log(`   GEMINI_API_KEY: ${CONFIG.GEMINI_API_KEY ? 'âœ“' : 'âœ—'}`);
  console.log(`   HEDRA_API_KEY: ${CONFIG.HEDRA_API_KEY ? 'âœ“' : 'âœ—'}`);
  console.log(`   ELEVENLABS_API_KEY: ${CONFIG.ELEVENLABS_API_KEY ? 'âœ“' : 'âœ—'}`);
  console.log(`   OPENAI_API_KEY: ${CONFIG.OPENAI_API_KEY ? 'âœ“' : 'âœ—'}`);
  console.log(`   MUSICAPI_KEY: ${CONFIG.MUSICAPI_KEY ? 'âœ“' : 'âœ—'}`);
  console.log(`   CREATOMATE_API_KEY: ${CONFIG.CREATOMATE_API_KEY ? 'âœ“' : 'âœ—'}`);

  // Step 1: ê¸°ì¡´ ì´ë¯¸ì§€ ë¡œë“œ
  const images = loadExistingImages(script);
  if (images.length === 0) {
    console.error('\nâŒ ì´ë¯¸ì§€ ì—†ìŒ');
    process.exit(1);
  }

  // Step 2: TTS ìŒì„± ìƒì„± (ElevenLabs)
  const audioFiles = await generateTTS(script);

  // Step 3: ìë§‰ ìƒì„± (Whisper ë˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ ê¸°ë°˜)
  const subtitles = await generateSubtitles(audioFiles, script);

  // Step 4: ë¹„ë””ì˜¤ ìƒì„± (Speakerë³„ ë¶„ê¸°)
  const videos = await generateVideos(images, audioFiles, script);

  // Step 5: BGM ìƒì„±
  const bgmUrl = await generateBGM(script);

  // Step 6: ìµœì¢… í•©ì„±
  await composeFinalVideo(videos, subtitles, script, bgmUrl);

  // ìŠ¤í¬ë¦½íŠ¸ ì €ì¥
  const scriptPath = path.join(outputFolder, 'script.json');
  fs.writeFileSync(scriptPath, JSON.stringify(script, null, 2));

  // ê²°ê³¼ ìš”ì•½
  console.log('\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log('  ğŸ“Š ê²°ê³¼ ìš”ì•½');
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log(`  ğŸ“¸ ì´ë¯¸ì§€: ${images.length}ê°œ (ê¸°ì¡´)`);
  console.log(`  ğŸ¤ TTS ìŒì„±: ${audioFiles.length}ê°œ`);
  console.log(`  ğŸ“ ìë§‰: ${subtitles.length}ê°œ ì„¸ê·¸ë¨¼íŠ¸`);
  console.log(`  ğŸ¬ ë¹„ë””ì˜¤: ${videos.length}ê°œ`);
  console.log(`     - Hedra (ë¦½ì‹±í¬): ${videos.filter(v => v.source === 'hedra').length}ê°œ`);
  console.log(`     - Veo (ëª¨ì…˜): ${videos.filter(v => v.source === 'veo').length}ê°œ`);
  console.log(`  ğŸµ BGM: ${bgmUrl ? 'âœ“' : 'âœ—'}`);
  console.log(`  ğŸ“ ì¶œë ¥: ${outputFolder}`);
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
}

// ì‹¤í–‰
main().catch(console.error);
