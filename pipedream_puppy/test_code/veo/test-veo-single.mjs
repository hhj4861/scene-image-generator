/**
 * Veo + ê¸°ì¡´ TTS ë‹¨ì¼ í…ŒìŠ¤íŠ¸
 * ê¸°ì¡´ ì´ë¯¸ì§€ì™€ ì˜¤ë””ì˜¤ë¥¼ í™œìš©í•´ì„œ Veo ë¦½ì‹±í¬ í…ŒìŠ¤íŠ¸
 */

import axios from 'axios';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import { execSync } from 'child_process';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const CONFIG = {
  GEMINI_API_KEY: process.env.GEMINI_API_KEY || '',
  // ê¸°ì¡´ í…ŒìŠ¤íŠ¸ í´ë”
  TEST_FOLDER: 'test_20251129_348fc310',
  OUTPUT_DIR: path.join(__dirname, 'test_output'),
};

// TTS ê¸¸ì´ í™•ì¸ (ffprobe)
function getAudioDuration(audioPath) {
  try {
    const result = execSync(`ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 "${audioPath}"`);
    return parseFloat(result.toString().trim());
  } catch (e) {
    console.log('   ffprobe ì‹¤íŒ¨, ê¸°ë³¸ê°’ 5ì´ˆ ì‚¬ìš©');
    return 5;
  }
}

// Veoë¡œ ì˜ìƒ ìƒì„±
async function generateVeoVideo(imageFile, prompt, durationSeconds, outputPath) {
  console.log(`   Veo ì˜ìƒ ìƒì„± ìš”ì²­...`);
  console.log(`   í”„ë¡¬í”„íŠ¸: "${prompt}"`);
  console.log(`   ê¸¸ì´: ${durationSeconds}ì´ˆ`);

  const imageBuffer = fs.readFileSync(imageFile);
  const imageBase64 = imageBuffer.toString('base64');

  const requestBody = {
    instances: [{
      prompt: prompt,
      image: {
        bytesBase64Encoded: imageBase64,
        mimeType: 'image/png'
      }
    }],
    parameters: {
      aspectRatio: '9:16',
      sampleCount: 1,
      durationSeconds: Math.max(5, Math.min(8, Math.ceil(durationSeconds))),
      personGeneration: 'dont_allow',
      negativePrompt: 'text, watermark, letters, subtitles, captions, words, typography, writing, characters, logo, label, title, credits, UI, overlay, banner, sign'
    }
  };

  const endpoint = `https://generativelanguage.googleapis.com/v1beta/models/veo-2.0-generate-001:predictLongRunning`;

  const response = await axios.post(endpoint, requestBody, {
    headers: { 'Content-Type': 'application/json', 'X-goog-api-key': CONFIG.GEMINI_API_KEY }
  });

  const operationName = response.data.name;
  console.log(`   Operation: ${operationName}`);

  // ì™„ë£Œ ëŒ€ê¸°
  let videoResult = null;
  for (let i = 0; i < 120; i++) {
    await new Promise(r => setTimeout(r, 5000));

    const statusResponse = await axios.get(
      `https://generativelanguage.googleapis.com/v1beta/${operationName}`,
      { headers: { 'X-goog-api-key': CONFIG.GEMINI_API_KEY } }
    );

    const status = statusResponse.data;
    console.log(`   [${(i + 1) * 5}ì´ˆ] done: ${status.done || false}`);

    if (status.done) {
      if (status.error) {
        throw new Error(JSON.stringify(status.error));
      }
      videoResult = status.response;
      break;
    }
  }

  if (!videoResult) throw new Error('Veo íƒ€ì„ì•„ì›ƒ');

  // ë¹„ë””ì˜¤ ì €ì¥
  const samples = videoResult.generateVideoResponse?.generatedSamples || videoResult.generatedSamples;
  if (samples && samples.length > 0) {
    const videoData = samples[0].video;
    if (videoData?.bytesBase64Encoded) {
      const videoBuffer = Buffer.from(videoData.bytesBase64Encoded, 'base64');
      fs.writeFileSync(outputPath, videoBuffer);
      console.log(`   âœ“ Veo ì˜ìƒ ì €ì¥: ${(videoBuffer.length / 1024 / 1024).toFixed(2)} MB`);
      return outputPath;
    } else if (videoData?.uri) {
      const videoResponse = await axios.get(videoData.uri, {
        responseType: 'arraybuffer',
        headers: { 'X-goog-api-key': CONFIG.GEMINI_API_KEY }
      });
      fs.writeFileSync(outputPath, Buffer.from(videoResponse.data));
      console.log(`   âœ“ Veo ì˜ìƒ ì €ì¥: ${(videoResponse.data.byteLength / 1024 / 1024).toFixed(2)} MB`);
      return outputPath;
    }
  }

  throw new Error('Veo ì‘ë‹µì— ë¹„ë””ì˜¤ ì—†ìŒ');
}

// FFmpegë¡œ ì˜ìƒê³¼ ìŒì„± í•©ì„±
function combineVideoAudio(videoPath, audioPath, outputPath) {
  console.log(`   FFmpeg í•©ì„± ì¤‘...`);
  const cmd = `ffmpeg -y -i "${videoPath}" -i "${audioPath}" -c:v copy -c:a aac -map 0:v:0 -map 1:a:0 -shortest "${outputPath}"`;
  try {
    execSync(cmd, { stdio: 'pipe' });
    console.log(`   âœ“ í•©ì„± ì™„ë£Œ: ${outputPath}`);
    return outputPath;
  } catch (e) {
    console.error('   FFmpeg ì˜¤ë¥˜:', e.message);
    throw e;
  }
}

async function testVeoSingle() {
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log('  ğŸ¬ Veo ë‹¨ì¼ í…ŒìŠ¤íŠ¸ (ê¸°ì¡´ ì´ë¯¸ì§€/ì˜¤ë””ì˜¤ í™œìš©)');
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.log();

  if (!CONFIG.GEMINI_API_KEY) {
    console.error('âŒ GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
    process.exit(1);
  }

  const outputFolder = path.join(CONFIG.OUTPUT_DIR, CONFIG.TEST_FOLDER);
  const imageFile = path.join(outputFolder, 'scene_001.png');
  const audioFile = path.join(outputFolder, 'audio_001.mp3');

  if (!fs.existsSync(imageFile)) {
    console.error('âŒ ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ:', imageFile);
    process.exit(1);
  }
  if (!fs.existsSync(audioFile)) {
    console.error('âŒ ì˜¤ë””ì˜¤ íŒŒì¼ ì—†ìŒ:', audioFile);
    process.exit(1);
  }

  console.log(`ğŸ“ ì´ë¯¸ì§€: ${imageFile}`);
  console.log(`ğŸµ ì˜¤ë””ì˜¤: ${audioFile}`);
  console.log();

  // ì˜¤ë””ì˜¤ ê¸¸ì´ í™•ì¸
  const audioDuration = getAudioDuration(audioFile);
  console.log(`ğŸ¤ ì˜¤ë””ì˜¤ ê¸¸ì´: ${audioDuration.toFixed(2)}ì´ˆ`);
  console.log();

  try {
    // ê¸°ì¡´ ì˜ ì‘ë™í–ˆë˜ í”„ë¡¬í”„íŠ¸ (í…ìŠ¤íŠ¸ ê´€ë ¨ ì œê±° - negativePromptë¡œ ì²˜ë¦¬)
    const veoPrompt = `A cute fluffy Pomeranian puppy talking and speaking with mouth opening and closing naturally, the dog is looking at the camera with bright expressive eyes, mouth movements as if speaking Korean words, subtle head tilts, warm cozy living room background, high quality animation, clean frame`;

    console.log('ğŸ¬ [STEP 1] Veo ì˜ìƒ ìƒì„±...');
    console.log(`   í”„ë¡¬í”„íŠ¸: "${veoPrompt.substring(0, 80)}..."`);

    const veoVideoPath = path.join(outputFolder, 'veo_single_test_raw.mp4');
    await generateVeoVideo(imageFile, veoPrompt, audioDuration, veoVideoPath);
    console.log();

    // FFmpeg í•©ì„±
    console.log('ğŸ”— [STEP 2] FFmpeg í•©ì„±...');
    const finalVideoPath = path.join(outputFolder, 'veo_single_test_final.mp4');
    combineVideoAudio(veoVideoPath, audioFile, finalVideoPath);

    const finalStats = fs.statSync(finalVideoPath);
    console.log();
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    console.log('  âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!');
    console.log(`  ğŸ“ ì›ë³¸ ì˜ìƒ: ${veoVideoPath}`);
    console.log(`  ğŸ“ í•©ì„± ì˜ìƒ: ${finalVideoPath}`);
    console.log(`  ğŸ“Š í¬ê¸°: ${(finalStats.size / 1024 / 1024).toFixed(2)} MB`);
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

  } catch (error) {
    console.error();
    console.error('âŒ ì˜¤ë¥˜:');
    console.error('   ìƒíƒœ ì½”ë“œ:', error.response?.status);
    console.error('   ì‘ë‹µ:', JSON.stringify(error.response?.data, null, 2));
    console.error('   ë©”ì‹œì§€:', error.message);
    process.exit(1);
  }
}

testVeoSingle();
